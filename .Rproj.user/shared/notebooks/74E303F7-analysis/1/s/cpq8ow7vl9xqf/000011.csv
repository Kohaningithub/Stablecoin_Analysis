"0","    "
"0","    # Predictive modeling with cross-validation"
"0","    if(requireNamespace(""caret"", quietly = TRUE)) {"
"0","      library(caret)"
"0","      "
"0","      # Prepare data for prediction"
"0","      ustc_pred_data <- ustc_early_warning %>%"
"0","        select(date, peg_deviation, significant_depeg, "
"0","               peg_deviation_lag1, peg_deviation_lag2, peg_deviation_lag3,"
"0","               volatility, volatility_lag1, volatility_lag2, volatility_lag3,"
"0","               volume, volume_change, period) %>%"
"0","        filter(complete.cases(.))"
"0","      "
"0","      # Split into pre-crash and crash/post-crash"
"0","      pre_crash_data <- ustc_pred_data %>% filter(date < as.Date(""2022-05-08""))"
"0","      crash_data <- ustc_pred_data %>% filter(date >= as.Date(""2022-05-08""))"
"0","      "
"0","      # Check if we have enough data"
"0","      if(nrow(pre_crash_data) >= 10 && nrow(crash_data) >= 5) {"
"0","        cat(""\nPredicting UST collapse using pre-crash data to predict crash behavior...\n"")"
"0","        "
"0","        # Set up cross-validation"
"0","        train_control <- trainControl("
"0","          method = ""cv"","
"0","          number = 5,"
"0","          classProbs = TRUE,"
"0","          summaryFunction = twoClassSummary,"
"0","          verboseIter = TRUE"
"0","        )"
"0","        "
"0","        # Train models to predict significant depegging"
"0","        set.seed(123)"
"0","        "
"0","        # Logistic Regression"
"0","        log_model <- train("
"0","          significant_depeg ~ peg_deviation_lag1 + peg_deviation_lag2 + "
"0","                             volatility_lag1 + volume_change,"
"0","          data = pre_crash_data,"
"0","          method = ""glm"","
"0","          family = ""binomial"","
"0","          trControl = train_control,"
"0","          metric = ""ROC"""
"0","        )"
"0","        "
"0","        # Random Forest"
"0","        rf_model <- train("
"0","          significant_depeg ~ peg_deviation_lag1 + peg_deviation_lag2 + "
"0","                            volatility_lag1 + volume_change,"
"0","          data = pre_crash_data,"
"0","          method = ""rf"","
"0","          trControl = train_control,"
"0","          metric = ""ROC"""
"0","        )"
"0","        "
"0","        # Print model results"
"0","        cat(""\nLogistic Regression Performance:\n"")"
"0","        print(log_model)"
"0","        "
"0","        cat(""\nRandom Forest Performance:\n"")"
"0","        print(rf_model)"
"0","        "
"0","        # Test on crash data"
"0","        log_preds <- predict(log_model, newdata = crash_data, type = ""prob"")[,""TRUE""]"
"0","        rf_preds <- predict(rf_model, newdata = crash_data, type = ""prob"")[,""TRUE""]"
"0","        "
"0","        # Create prediction dataset"
"0","        crash_preds <- crash_data %>%"
"0","          select(date, peg_deviation, significant_depeg) %>%"
"0","          mutate("
"0","            log_pred_prob = log_preds,"
"0","            rf_pred_prob = rf_preds"
"0","          )"
"0","        "
"0","        # Visualize predictions vs actual for each model"
"0","        for(token_name in unique(prediction_data$token)) {"
"0","          token_data <- prediction_data %>% filter(token == token_name)"
"0","          "
"0","          # Create a data frame for plotting"
"0","          scatter_data <- data.frame("
"0","            actual = token_data$peg_deviation,"
"0","            lm = predict(model_objects[[token_name]]$lm, newdata = token_data),"
"0","            rf = predict(model_objects[[token_name]]$rf, newdata = token_data),"
"0","            dt = predict(model_objects[[token_name]]$dt, newdata = token_data)"
"0","          ) %>%"
"0","            pivot_longer(cols = c(lm, rf, dt), "
"0","                        names_to = ""model"", "
"0","                        values_to = ""predicted"")"
"0","          "
"0","          # Add model labels for the legend"
"0","          scatter_data$model <- factor(scatter_data$model,"
"0","                                      levels = c(""lm"", ""rf"", ""dt""),"
"0","                                      labels = c(""Linear Model"", ""Random Forest"", ""Decision Tree""))"
"0","          "
"0","          # Create an improved scatter plot"
"0","          p2 <- ggplot(scatter_data, aes(x = actual, y = predicted, color = model)) +"
"0","            geom_point(size = 3, alpha = 0.7) +"
"0","            # Add perfect prediction line"
"0","            geom_abline(intercept = 0, slope = 1, linetype = ""dashed"", color = ""gray50"") +"
"0","            # Add model-specific trend lines"
"0","            geom_smooth(method = ""lm"", se = FALSE, linetype = ""solid"", size = 0.7) +"
"0","            # Add annotation explaining the plot"
"0","            annotate(""text"", x = min(scatter_data$actual), "
"0","                     y = max(scatter_data$predicted) * 0.9,"
"0","                     label = ""Points on dashed line = perfect prediction"","
"0","                     hjust = 0, fontface = ""italic"", size = 3) +"
"0","            # Improve labels and styling"
"0","            labs(title = paste(""Actual vs. Predicted Peg Deviation for"", token_name),"
"0","                 subtitle = ""Closer to dashed line indicates better prediction accuracy"","
"0","                 x = ""Actual Peg Deviation"", "
"0","                 y = ""Predicted Peg Deviation"","
"0","                 color = ""Model Type"") +"
"0","            theme_minimal() +"
"0","            theme("
"0","              legend.position = ""bottom"","
"0","              plot.subtitle = element_text(size = 9, color = ""darkgray"")"
"0","            )"
"0","          print(p2)"
"0","          save_last_plot(paste0(""actual_vs_predicted_"", token_name))"
"0","        }"
"0","        "
"0","        # Variable importance"
"0","        if(requireNamespace(""vip"", quietly = TRUE)) {"
"0","          library(vip)"
"0","          p_imp <- vip(rf_model, num_features = 10)"
"0","          print(p_imp)"
"0","        }"
"0","        "
"0","        # Calculate how many days in advance the models predicted the collapse"
"0","        warning_threshold <- 0.7  # 70% probability as warning threshold"
"0","        "
"0","        # Find first day with high warning"
"0","        first_warning_log <- crash_preds %>%"
"0","          filter(log_pred_prob > warning_threshold) %>%"
"0","          arrange(date) %>%"
"0","          slice(1)"
"0","        "
"0","        first_warning_rf <- crash_preds %>%"
"0","          filter(rf_pred_prob > warning_threshold) %>%"
"0","          arrange(date) %>%"
"0","          slice(1)"
"0","        "
"0","        # Find first day with significant depegging"
"0","        first_depeg <- crash_preds %>%"
"0","          filter(significant_depeg == TRUE) %>%"
"0","          arrange(date) %>%"
"0","          slice(1)"
"0","        "
"0","        if(nrow(first_warning_log) > 0 && nrow(first_depeg) > 0) {"
"0","          warning_days_log <- as.numeric(difftime(first_depeg$date, first_warning_log$date, units = ""days""))"
"0","          cat(""\nLogistic Regression model provided warning"", warning_days_log, ""days before significant depegging\n"")"
"0","        }"
"0","        "
"0","        if(nrow(first_warning_rf) > 0 && nrow(first_depeg) > 0) {"
"0","          warning_days_rf <- as.numeric(difftime(first_depeg$date, first_warning_rf$date, units = ""days""))"
"0","          cat(""Random Forest model provided warning"", warning_days_rf, ""days before significant depegging\n"")"
"0","        }"
"0","      } else {"
"0","        cat(""Insufficient data for cross-validated prediction modeling\n"")"
"0","      }"
"0","    } else {"
"0","      cat(""Package 'caret' not available for cross-validation\n"")"
"0","    }"
"1","Insufficient data for cross-validated prediction modeling
"
"0","  } else {"
"2","Error: unexpected '}' in ""  }""
"
